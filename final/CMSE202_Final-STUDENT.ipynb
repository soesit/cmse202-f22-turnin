{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exam (Individual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Sit Soe.</p>\n",
    "### <p style=\"text-align: right;\"> &#9989; soesit.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Fall 2022)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be committing and pushing repository changes to a GitHub repository, working with data to build a network graph, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, you'll probably want to make sure you do Part 1 first to ensure that your GitHub repository is working correctly. Let your instructor know right away if you run into issues!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "If you have any questions during the exam, you may ask the instructor, the TA, or the LA privately. If you are attending in-person, simply raise your hand and one of us will come over to you. If you are attending via-Zoom, please use the ask-for-help feature or privately message the instructor, the TA, or the LA. We will make any announcements or exam clarifications/corrections to the class via the following Google Document.\n",
    "\n",
    "[LINK]\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. **However**: The use of any person-to-person communication software is absolutely not acceptable. If you are seen accessing your email, using a chat program (e.g. Slack), or any sort of collaborative cloud storage or document software (e.g. Google Documents other than the one we will make announcements on), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Keep your eyes on your screen!** This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "\n",
    "0. [Part 0: Upgrade packages](#part0) (1 point)\n",
    "\n",
    "1. [Part 1: Git](#part1) (9 points)\n",
    "\n",
    "2. [Part 2: Data Preprocessing](#part2) (20 points)\n",
    "\n",
    "3. [Part 3: Regression](#part3) (15 points)\n",
    "\n",
    "4. [Part 4: Principal Component Analysis](#part4) (12 points)\n",
    "\n",
    "5. [Part 5: Support Vector Machines](#part5) (15 points)\n",
    "\n",
    "6. [Part 6: Regression Redux](#part6) (7 points)\n",
    "\n",
    "7. [Part 7: Conceptual Questions](#part7) (14 points)\n",
    "\n",
    "8. [Part 8: Conclusion](#conclusion) (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:50:14.352819Z",
     "start_time": "2022-12-07T03:50:14.350105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total grade for this final is 96\n"
     ]
    }
   ],
   "source": [
    "grades = [1, 9, 20, 15, 12, 15, 7, 14, 3]\n",
    "\n",
    "print(f\"The total grade for this final is {sum(grades)}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part0\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 0: Upgrade Packages\n",
    "\n",
    "**&#9989; Question 0.1 (1 point)**: Run the cell below. Do you have the correct packages ? If not upgrade them. **You must do this in order to avoid issues in the rest of the notebook.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:15:16.292936Z",
     "start_time": "2022-12-07T03:15:16.283043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Sklearn version should be 1.1.3 and I have 1.1.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standard libraries\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Data cleaning Libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.utils import resample\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "import statsmodels.api as sm \n",
    "\n",
    "from sklearn import __version__ as sk_version\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "print(f\"Sklearn version should be 1.1.3 and I have {sk_version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part1\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 1: Git (9 points)\n",
    "\n",
    "For this assignment, you're going to add it to the `cmse202-f22-turnin` repository you created in class so that you can track your progress on the assignment and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Question 1.1 (1 point)**: Navigate to your `cmse202-f22-turnin` **local** repository and create a new directory called `final` and copy this notebook in that new directory.\n",
    "\n",
    "``` bash\n",
    "# Put the command(s) for creating the new directory\n",
    "\n",
    "```\n",
    "mkdir final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.2 (3 points)** Check the status of your local `git`.\n",
    "\n",
    "``` bash \n",
    "# Put the command you used to check the status of git\n",
    "\n",
    "```\n",
    "git status \n",
    "Copy and paste below the output of the command.\n",
    "\n",
    "``` bash\n",
    "# Paste it here\n",
    "```\n",
    "Changes to be committed:\n",
    "  (use \"git restore --staged <file>...\" to unstage)\n",
    "        new file:   ../Project /FirstYearGPA.csv\n",
    "\n",
    "Changes not staged for commit:\n",
    "  (use \"git add/rm <file>...\" to update what will be committed)\n",
    "  (use \"git restore <file>...\" to discard changes in working directory)\n",
    "        deleted:    ../CMSE202_Midterm_Sect01_STUDENT.ipynb\n",
    "        deleted:    ../Project /FirstYearGPA.csv\n",
    "        modified:   ../hw-02/.ipynb_checkpoints/HW-02_PandasAndObjects-STUDENT-checkpoint.ipynb\n",
    "        modified:   ../hw-04/HW-04_Regression-STUDENT.ipynb\n",
    "        modified:   ../midterm/CMSE202_Midterm_Sect01_STUDENT.ipynb\n",
    "\n",
    "Untracked files:\n",
    "  (use \"git add <file>...\" to include in what will be committed)\n",
    "        ./\n",
    "        ../hw-03/.ipynb_checkpoints/\n",
    "        ../hw-03/asoiaf-book1-edges.csv\n",
    "        ../hw-03/store_placement.py\n",
    "        ../hw-04/.ipynb_checkpoints/\n",
    "        ../hw-04/ads.csv\n",
    "        ../hw-04/housing.csv\n",
    "        ../midterm/.ipynb_checkpoints/\n",
    "        ../midterm/metadata.csv\n",
    "        ../midterm/spectra_data.csv \n",
    "\n",
    "What is the name of the branch you are in ? \n",
    "\n",
    "``` bash\n",
    "# Put your answer here\n",
    "```\n",
    "    git branch\n",
    "    main\n",
    "\n",
    "**Important:** You should be in the `main` branch. If you are not switch to the `main` branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.3 (3 points):**\n",
    "Add your name and GitHub username to the top of the notebook, then add and commit **ONLY** the notebook.\n",
    "\n",
    "``` bash\n",
    "# Put the command(s) to add and commit here \n",
    "```\n",
    "git add\n",
    "git commit -m 'First commit' \n",
    "git push\n",
    "\n",
    "What is the commit message you used ?\n",
    "\n",
    "``` bash\n",
    "# Answer the question here\n",
    "```\n",
    "First commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.4 (1 point):** Before moving on. Check that the notebook you are working on is the correct one. Run the following cell. **Are you in the new folder you just created?** If not close this notebook and open the one in the `final` folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:32.165597Z",
     "start_time": "2022-12-05T20:23:31.986031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soesit/CMSE202/repositories/cmse202-f22-turnin/final\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.5 (1 point):** Finally push the updated notebook to GitHub.\n",
    "\n",
    "``` bash\n",
    "# Put the command you used to push to GitHub here.\n",
    "```\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" repository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the notebook, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-f22-turnin`\" repository inside the `final` directory that you just created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "<a id=\"part2\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 2. Data preprocessing (19 points)\n",
    "\n",
    "For this assignment we’re going to be working with a dataset that contains measurements of the characteristics of multiple wines. This includes things like the acidity and density. You’ll be asked to use this information, along with the machine learning tools that we’ve used in class, to determine whether the wine type is Red or White.\n",
    "\n",
    "The dataset is located at:\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-F22-data/main/data/winequality.csv`\n",
    "\n",
    "\n",
    "**&#9989; Question 2.1 (4 points):** Do this\n",
    "\n",
    "1. Download the data and type the command you used to download the data\n",
    "\n",
    "2. Read the `winequality.csv` file into a dataframe\n",
    "\n",
    "3. Print out the **unique** labels in the `type` column. \n",
    "\n",
    "4. Display the first 10 rows of the dataset.\n",
    "\n",
    "**Note**: each row represents one data point and each column (except the `type` column) represents one feature. The `type` column corresponds to the class labels for every data point. There are two types of unique class labels in the `type` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:35.697903Z",
     "start_time": "2022-12-05T20:23:35.694510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  381k  100  381k    0     0  77332      0  0:00:05  0:00:05 --:--:-- 85552\n"
     ]
    }
   ],
   "source": [
    "# Put the command you used to download the data here\n",
    "!curl -O https://raw.githubusercontent.com/msu-cmse-courses/cmse202-F22-data/main/data/winequality.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:36.383889Z",
     "start_time": "2022-12-05T20:23:36.381940Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>white</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>white</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0  white            7.0              0.27         0.36            20.7   \n",
       "1  white            6.3              0.30         0.34             1.6   \n",
       "2  white            8.1              0.28         0.40             6.9   \n",
       "3  white            7.2              0.23         0.32             8.5   \n",
       "4  white            7.2              0.23         0.32             8.5   \n",
       "5  white            8.1              0.28         0.40             6.9   \n",
       "6  white            6.2              0.32         0.16             7.0   \n",
       "7  white            7.0              0.27         0.36            20.7   \n",
       "8  white            6.3              0.30         0.34             1.6   \n",
       "9  white            8.1              0.22         0.43             1.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "5      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "6      0.045                 30.0                 136.0   0.9949  3.18   \n",
       "7      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "8      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "9      0.044                 28.0                 129.0   0.9938  3.22   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.45      8.8        6  \n",
       "1       0.49      9.5        6  \n",
       "2       0.44     10.1        6  \n",
       "3       0.40      9.9        6  \n",
       "4       0.40      9.9        6  \n",
       "5       0.44     10.1        6  \n",
       "6       0.47      9.6        6  \n",
       "7       0.45      8.8        6  \n",
       "8       0.49      9.5        6  \n",
       "9       0.45     11.0        6  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "wine_data = pd.read_csv('winequality.csv')\n",
    "wine_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**&#9989; Question 2.2 (7 points):** Do the following:\n",
    "\n",
    "1. Drop the `NaN` in the dataset\n",
    "\n",
    "2. Drop the `quality` column\n",
    "\n",
    "2. Replace all of the strings in your `type` column with integers based on the following:\n",
    "\n",
    "    | original type | integer type |\n",
    "    | -------- | -------- |\n",
    "    | white | 0 |\n",
    "    | red | 1 |\n",
    "\n",
    "3. Once you've replaced the labels, display your DataFrame and confirm that it looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:22:13.098444Z",
     "start_time": "2022-12-07T03:22:13.095245Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0     0            7.0              0.27         0.36            20.7   \n",
       "1     0            6.3              0.30         0.34             1.6   \n",
       "2     0            8.1              0.28         0.40             6.9   \n",
       "3     0            7.2              0.23         0.32             8.5   \n",
       "4     0            7.2              0.23         0.32             8.5   \n",
       "5     0            8.1              0.28         0.40             6.9   \n",
       "6     0            6.2              0.32         0.16             7.0   \n",
       "7     0            7.0              0.27         0.36            20.7   \n",
       "8     0            6.3              0.30         0.34             1.6   \n",
       "9     0            8.1              0.22         0.43             1.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "5      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "6      0.045                 30.0                 136.0   0.9949  3.18   \n",
       "7      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "8      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "9      0.044                 28.0                 129.0   0.9938  3.22   \n",
       "\n",
       "   sulphates  alcohol  \n",
       "0       0.45      8.8  \n",
       "1       0.49      9.5  \n",
       "2       0.44     10.1  \n",
       "3       0.40      9.9  \n",
       "4       0.40      9.9  \n",
       "5       0.44     10.1  \n",
       "6       0.47      9.6  \n",
       "7       0.45      8.8  \n",
       "8       0.49      9.5  \n",
       "9       0.45     11.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "wine_data = wine_data.dropna()\n",
    "wine_data = wine_data.drop(['quality'], axis=1)\n",
    "wine_data['type'] = wine_data['type'].replace({'white': 0, 'red': 1})\n",
    "wine_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**&#9989; Question 2.3 (2 points):** As we've seen, when working with `scikit-learn` it can be much easier to work with the data if we have separate variables: one that stores the feature matrix and one that stores the class labels.\n",
    "\n",
    "**Do This:** Split your DataFrame so that you have two separate DataFrames: (1) one called `features`, which contains all columns of features; and (2) one called `labels`, which is a single-column dataframe that contains all of the *new* integer labels you just created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:22:14.395392Z",
     "start_time": "2022-12-07T03:22:14.392835Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6463 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0             0.270         0.36            20.7      0.045   \n",
       "1               6.3             0.300         0.34             1.6      0.049   \n",
       "2               8.1             0.280         0.40             6.9      0.050   \n",
       "3               7.2             0.230         0.32             8.5      0.058   \n",
       "4               7.2             0.230         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "6491            6.8             0.620         0.08             1.9      0.068   \n",
       "6492            6.2             0.600         0.08             2.0      0.090   \n",
       "6494            6.3             0.510         0.13             2.3      0.076   \n",
       "6495            5.9             0.645         0.12             2.0      0.075   \n",
       "6496            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "6491                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "6492                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "6494                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "6495                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "6496                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         8.8  \n",
       "1         9.5  \n",
       "2        10.1  \n",
       "3         9.9  \n",
       "4         9.9  \n",
       "...       ...  \n",
       "6491      9.5  \n",
       "6492     10.5  \n",
       "6494     11.0  \n",
       "6495     10.2  \n",
       "6496     11.0  \n",
       "\n",
       "[6463 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here\n",
    "features = wine_data.iloc[:,1:]\n",
    "labels = wine_data.iloc[:,0]\n",
    "features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 2.4 (1 points):** Do this:\n",
    "\n",
    "We need to scale the data. This isn't something we've talked very much about in-class, so we don't expect you to know exactly what is happening here. But it will be important for our PCA later on in the assignment. We decided to put it here so you were aware of it's existence. \n",
    "\n",
    "**Run the following bit of code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:22:15.765193Z",
     "start_time": "2022-12-07T03:22:15.598135Z"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(PowerTransformer().fit_transform(features), \n",
    "                            columns=features.columns, \n",
    "                            index=features.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 2.5 (3 points):** Do this:\n",
    "\n",
    "1. Split your data into a training and a testing set with a training set representing 75% of your data. For reproducibility , set the `random_state` argument to `314159`. \n",
    "\n",
    "2. Print the lengths to show you have the right number of entries for the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4847\n",
      "1616\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                    test_size=0.25, random_state=314159)\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 2\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 3. Regression (15 Points)\n",
    "\n",
    "**&#9989; Question 3.1.1 (3 points):**\n",
    "Let's start making some prediction. \n",
    "\n",
    "1. Make a Logistic Regression model using `statsmodels` for predicting the type of wine. \n",
    "\n",
    "2. Print out the summary of your model fits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.193646\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   type   No. Observations:                 4847\n",
      "Model:                          Logit   Df Residuals:                     4837\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 13 Dec 2022   Pseudo R-squ.:                  0.6530\n",
      "Time:                        21:47:35   Log-Likelihood:                -938.60\n",
      "converged:                      False   LL-Null:                       -2704.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "fixed acidity            1.4959      0.115     12.993      0.000       1.270       1.722\n",
      "volatile acidity         1.3956      0.084     16.677      0.000       1.232       1.560\n",
      "citric acid             -0.3490      0.083     -4.220      0.000      -0.511      -0.187\n",
      "residual sugar           0.2031      0.107      1.892      0.059      -0.007       0.413\n",
      "chlorides                1.5281      0.090     16.920      0.000       1.351       1.705\n",
      "free sulfur dioxide      1.0362      0.104      9.995      0.000       0.833       1.239\n",
      "total sulfur dioxide    -3.5030      0.160    -21.936      0.000      -3.816      -3.190\n",
      "density              -1.389e-05   9.99e+13  -1.39e-19      1.000   -1.96e+14    1.96e+14\n",
      "pH                       0.8843      0.085     10.438      0.000       0.718       1.050\n",
      "sulphates                0.8976      0.074     12.125      0.000       0.753       1.043\n",
      "alcohol                 -0.1330      0.123     -1.082      0.279      -0.374       0.108\n",
      "========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.15 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soesit/.local/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model1 = sm.Logit(y_train, X_train)\n",
    "result1 = model1.fit()\n",
    "\n",
    "# Print the summary results\n",
    "print(result1.summary())\n",
    "\n",
    "# Predict the labels on the test data\n",
    "y_pred1 = result1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 3.1.2 (2 points):** Further examine the results by  \n",
    "\n",
    "1. printing a classification report\n",
    "2. making a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:26:35.328300Z",
     "start_time": "2022-12-07T03:26:35.326261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1216\n",
      "           1       0.76      1.00      0.86       400\n",
      "\n",
      "    accuracy                           0.92      1616\n",
      "   macro avg       0.88      0.95      0.90      1616\n",
      "weighted avg       0.94      0.92      0.92      1616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_binary1 = (y_pred > 0.5).astype(int) \n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1088  128]\n",
      " [   1  399]]\n"
     ]
    }
   ],
   "source": [
    "cm1 = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 3.2.1 (3 points):** Make an reduced Logistic Regression model for predicting the type of wine that uses just three parameters (two from the dataset + a constant). Print out the summary of your model fits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.456145\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   type   No. Observations:                 4847\n",
      "Model:                          Logit   Df Residuals:                     4844\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Wed, 14 Dec 2022   Pseudo R-squ.:                  0.1826\n",
      "Time:                        00:00:48   Log-Likelihood:                -2210.9\n",
      "converged:                       True   LL-Null:                       -2704.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.147e-215\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              4.6351      0.376     12.319      0.000       3.898       5.373\n",
      "residual sugar    -0.3624      0.016    -22.501      0.000      -0.394      -0.331\n",
      "alcohol           -0.4122      0.034    -11.965      0.000      -0.480      -0.345\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features1 = wine_data.loc[:, ['residual sugar', 'alcohol']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features1, labels, \n",
    "                                                    test_size=0.25, random_state=314159)\n",
    "# Add a constant term to the independent variable\n",
    "X_train2 = sm.add_constant(X_train)\n",
    "X_test2 = sm.add_constant(X_test)\n",
    "\n",
    "# Make a logistic regression model\n",
    "model2 = sm.Logit(y_train, X_train2)\n",
    "result2 = model2.fit()\n",
    "\n",
    "\n",
    "# Print the summary results\n",
    "print(result2.summary())\n",
    "\n",
    "# Predict the labels on the test data\n",
    "y_pred2 = result2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 3.2.2 (2 points):** Same as above, examine the results of your reduced model by printing a classification report and a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:29:01.144438Z",
     "start_time": "2022-12-07T03:29:01.142337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1216\n",
      "           1       0.76      1.00      0.86       400\n",
      "\n",
      "    accuracy                           0.92      1616\n",
      "   macro avg       0.88      0.95      0.90      1616\n",
      "weighted avg       0.94      0.92      0.92      1616\n",
      "\n",
      "[[1088  128]\n",
      " [   1  399]]\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "# Convert into binary\n",
    "y_pred_binary2 = (y_pred > 0.5).astype(int) \n",
    "report2 = classification_report(y_test, y_pred_binary2)\n",
    "print(report2)\n",
    "\n",
    "cm2 = confusion_matrix(y_test, y_pred_binary2)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 3.3 (3 points):** How did you pick the best parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I determined mainly on the P-Value and which had the lowest P-Values. After that I basically plugged and checked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 3\", and push the changes to GitHub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part4\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 4. Principal Component Analysis (12 points)\n",
    "\n",
    "The full model uses all 12 features to predict the results. In many cases, we might need to see how close we can get with fewer features. Instead of simply removing features, we will use a Principal Component Analysis (PCA) to determine the combined features that contribute the most to the model (through their accounted variance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**&#9989; Question 4.1 (5 points):** Run a Principle Component Analysis (PCA)\n",
    "\n",
    "Since we only have 12 features to start with, let's see how well we can do if we try to aggressively reduce the feature count and use only **2** principle components. \n",
    "\n",
    "1. Using `PCA()` and the associated methods, run a principle component analysis on your `features` dataset using only 2 components. \n",
    "\n",
    "2. Transform the dataset into a new dataset and call it `pca_features`. \n",
    "\n",
    "3. Print the `explained_variance_ratio_` and its sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:32:35.543453Z",
     "start_time": "2022-12-07T03:32:35.541284Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2745369 0.2286033]\n",
      "0.5031401988795946\n"
     ]
    }
   ],
   "source": [
    "# Standardize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_std = scaler.fit_transform(features)\n",
    "\n",
    "# Fit PCA to standardized data\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(data_std)\n",
    "\n",
    "# Transform data using fit_transform() method\n",
    "pca_features = pca.fit_transform(data_std)\n",
    "\n",
    "# View explained variance ratios\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Print sum of explained variance ratios\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&#9989; **Question 4.1.1 (2 points):** What is the **total** explained variance ratio captured by the 2 principle components? (just quote the number) How well do you think a model with these many features will perform? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font size=+3>&#9998;</font> The total explained variance ratio captured by the 2 principle components is 0.5031401988795946.\n",
    "\n",
    "A model with these many features may not perform reasonably well since the 2 principal components capture only half the  amount of the data's variance (50.31%). However, further evaluation of the model's performance using metrics such as accuracy, precision, and recall may be necessary to determine its actual performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 4.2 (3 points):** Do the following:\n",
    "\n",
    "1. Split your new features (`pca_features`) and corresponding labels (the labels are the same as before) into a training and a testing set, with the training set representing 75% of your data. For reproducibility, set the `random_state` argument to `314159`. \n",
    "\n",
    "2. Print the lengths to show you have the right number of entries.\n",
    "\n",
    "Basically do the same you have done in Q2.5 but with the `pca_features` dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:34:12.203423Z",
     "start_time": "2022-12-07T03:34:12.200976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4847\n",
      "1616\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_features, labels, \n",
    "                                                    test_size=0.25, random_state=314159)\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 4\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "<a id=\"part5\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 5. Support Vector Machine (15 points)\n",
    "\n",
    "Let's see how an SVM performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**&#9989; Question 5.1 (9 points):** Do the following:\n",
    "\n",
    "1. Build a `SVC` model with a `linear` kernel. (2 points), \n",
    "\n",
    "2. Use `GridSearchCV` to find the best `C` parameter from this list: `'C':[0.0001, 0.001, 0.1, 1, 10]`, (2 points)\n",
    "  \n",
    "3. **Fit** the above model on the training set and **print** the best estimator (2 points)\n",
    "\n",
    "4. Use your best estimator on the test dataset to make prediction. (1 point)\n",
    "\n",
    "5. Print a [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), based on its performance on the testing dataset. (1 point)\n",
    "\n",
    "6. Print the [confusion matrix](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py) on the testing dataset  (1 point)\n",
    "\n",
    "**Note:** You can set the `GridSearchCV` keyword argument `n_jobs = -1` to speed things up (this allows the process to run on multiple cores.)\n",
    "\n",
    "**Note:** If `GridSearchCV` is slow you can use the built-in model `LinearSVC` in `sklearn`. This is the same as `SVC(kernel = 'linear')` but it is faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:35:07.832760Z",
     "start_time": "2022-12-07T03:35:07.829838Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the SVC model with a linear kernel\n",
    "model = SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Best estimator found by grid search:\n",
      "SVC(C=0.001, kernel='linear')\n",
      "Best parameters found by grid search:\n",
      "{'C': 0.001, 'kernel': 'linear'}\n",
      "Runtime 1.6939733028411865\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#make some temporary variables so you can change this easily\n",
    "X_train = X_train\n",
    "y_train = y_train.astype(int)\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "# a dictionary of hyperparameters: key is the name of the parameter, value is a list of values to test\n",
    "#small gamma values\n",
    "param_grid = {'C': [0.0001, 0.001, 0.1, 1, 10],\n",
    "              'kernel': ['linear']}\n",
    "# make a classifier by searching over a classifier and the parameter grid\n",
    "clf = GridSearchCV(model, param_grid)\n",
    "\n",
    "# we have a \"good\" classifier (according to GridSearchCV), how's it look\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear', C=0.001)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred3 = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1216\n",
      "           1       0.98      0.96      0.97       400\n",
      "\n",
      "    accuracy                           0.99      1616\n",
      "   macro avg       0.98      0.98      0.98      1616\n",
      "weighted avg       0.99      0.99      0.99      1616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_binary3 = (y_pred > 0.5).astype(int) \n",
    "report3 = classification_report(y_test, y_pred_binary3)\n",
    "print(report3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1208    8]\n",
      " [  16  384]]\n"
     ]
    }
   ],
   "source": [
    "cm3 = confusion_matrix(y_test, y_pred_binary3)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 5.1.1 (4 points):** Answer the following questions:\n",
    "\n",
    "1. What is the accuracy score of your model ? **Do not use code** You should be able to read it from the output above!\n",
    "\n",
    "Accuracy socre is 0.99\n",
    "\n",
    "2. How does your SVM model compare with the Regression models? \n",
    " \n",
    " The percision and recall were both much more accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 5\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 6. Regression Redux (7 Points)\n",
    "\n",
    "**&#9989; Question 6.1.1 (3 points):** Let's investigate the Logistic model again and see how it performs on the new PCA-transformed dataset. \n",
    "\n",
    "**Do this**: Make an Logistic model using the PCA features (2 features + constant). You should add a constant to the two PCA features, giving you three total features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.057610\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   type   No. Observations:                 4847\n",
      "Model:                          Logit   Df Residuals:                     4844\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Wed, 14 Dec 2022   Pseudo R-squ.:                  0.8968\n",
      "Time:                        00:36:52   Log-Likelihood:                -279.23\n",
      "converged:                       True   LL-Null:                       -2704.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.7402      0.242    -19.576      0.000      -5.215      -4.266\n",
      "x1            -3.7158      0.177    -21.051      0.000      -4.062      -3.370\n",
      "x2            -0.3184      0.086     -3.689      0.000      -0.488      -0.149\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.29 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "X_train3 = sm.add_constant(X_train)\n",
    "X_test3 = sm.add_constant(X_test)\n",
    "\n",
    "# Make a logistic regression model\n",
    "model4 = sm.Logit(y_train, X_train3)\n",
    "result4 = model4.fit()\n",
    "\n",
    "\n",
    "# Print the summary results\n",
    "print(result4.summary())\n",
    "\n",
    "# Predict the labels on the test data\n",
    "y_pred4 = result4.predict(X_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 6.1.2 (2 points):**  Examine the results by making a confusion matrix (2 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:37:45.505079Z",
     "start_time": "2022-12-07T03:37:45.503036Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred_binary3 = (y_pred > 0.5).astype(int) \n",
    "\n",
    "\n",
    "cm3 = confusion_matrix(y_test, y_pred_binary3)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 6\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part7\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 7. Conceptual Questions (14 Points)\n",
    "\n",
    "**&#9989; Question 7.1 (4 points):** Compare your results from 3.2.2 and 6.1.2, two Logistic regression models that used the three most significant features. Which one performed better? Why? Your explanation should discuss the difference between the features in the two models and how that difference might affect how well the model fits the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.2 \n",
    "The following questions probe your understanding of  `recall` and `precision`. You’ll be given a specific scenario, and you will need to decide whether to select a Machine Learning model that maximizes `recall` or `precision`.\n",
    "\n",
    "\n",
    "**&#9989; Question 7.2.1 (4 points):**  A new disease has been detected in Sweden. Doctors have taken multiple measurements of patients and passed them along to you. You’ve tested various models to predict which patients have the new disease. The Swedish health experts have told you it is critical that they identify **all** of the patients with the new disease so they can put them into quarantine. They tell you that it doesn’t matter if your model accidentally flags some people as having the disease even when they don’t, as it’s much better to tell people who aren’t sick to quarantine than to tell a sick person they don’t need to quarantine.\n",
    "\n",
    "Given this situation, should you choose the model that maximizes `recall` or the model that maximizes `precision`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation, you should choose the model that maximizes recall. Recall is a measure of the ability of a model to correctly identify all patients with the disease, so it is more important to identify all patients with the disease in order to quarantine them and prevent the spread of the disease. It is better to accidentally flag some people as having the disease who don't actually have it, and tell them to quarantine, than to miss identifying patients with the disease and allowing them to spread the disease to others. Precision, on the other hand, is a measure of the ability of a model to correctly identify only those patients who actually have the disease, so it is not as important in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**&#9989; Question 7.2.2 (4 points):**\n",
    "You are working for the state of Michigan, helping them with their new unemployment insurance program. You’ve created various models that are meant to detect fraud–i.e., determine whether or not someone applied for unemployment insurance when they shouldn’t have. Your boss tells you that it’s critical that your model doesn’t accidentally accuse an innocent person of fraud. They say it’s fine if your model misses some people who committed fraud as long as there are no false accusations. \n",
    "\n",
    "Given this situation, should you choose the model that maximizes `recall` or the model that maximizes `precision`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation, you should choose the model that maximizes precision. Precision is a measure of the ability of a model to correctly identify only those people who actually committed fraud, so it is important in this situation to avoid falsely accusing innocent people. It is better to miss identifying some people who committed fraud than to falsely accuse innocent people, who could face negative consequences as a result. Recall, on the other hand, is a measure of the ability of a model to correctly identify all people who committed fraud, so it is not as important in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!** (2 points)\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 6\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"conclusion\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 8. Conclusion (3 points)\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub. \n",
    "Before you leave\n",
    "\n",
    "1. Have you added your name and github username at the top of this notebook? ? (1 point)\n",
    "\n",
    "2. Push the changes to your GitHub repository (1 point)\n",
    "\n",
    "3. Upload your notebook to D2L in case something went wrong with your repository or if you couldn't get the repository to work.  (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Midterm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:32:42.910515Z",
     "start_time": "2022-12-05T21:32:42.900046Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# FINAL GRADE (Instructor's use only)\",\n",
    "parts = [part_0, part_1, part_2, part_3, part_4, part_5, part_6, part_7]\n",
    "print(f\"Part 0: {part_0}/{grades[0]}\")\n",
    "print(f\"Part 1: {part_1}/{grades[1]}\")\n",
    "print(f\"Part 2: {part_2}/{grades[2]}\")\n",
    "print(f\"Part 3: {part_3}/{grades[3]}\")\n",
    "print(f\"Part 4: {part_4}/{grades[4]}\")\n",
    "print(f\"Part 5: {part_5}/{grades[5]}\")\n",
    "print(f\"Part 6: {part_6}/{grades[6]}\")\n",
    "print(f\"Part 7: {part_7}/{grades[7]}\")\n",
    "\n",
    "total = sum(parts)\n",
    "print(f\"Your final grade is {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright 2022,  Department of Computational Mathematics, Science and Engineering at Michigan State University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
